apiVersion: v1
kind: ConfigMap
metadata:
  name: prometheus-server-conf
  labels:
    name: prometheus-server-conf
  namespace: monitoring
data:
  prometheus.rules: |-
    groups:
    - name: alerts
      rules:
      - alert: High Node Memory
        expr: ((node_memory_MemTotal_bytes - node_memory_MemFree_bytes - node_memory_Cached_bytes - node_memory_SReclaimable_bytes - node_memory_Buffers_bytes)/node_memory_MemTotal_bytes)*100 > 90
        for: 3m
        labels:
          severity: mail
        annotations:
          summary: High Memory Usage
      - alert: High Swap Usage
        expr: ((node_memory_SwapTotal_bytes - node_memory_SwapFree_bytes)/node_memory_SwapTotal_bytes)*100 > 40
        for: 3m
        labels:
          severity: mail
        annotations:
          summary: High Swap Usage
      - alert: High Load Avarage
        expr: node_load5 > 20
        for: 5m
        labels:
          severity: mail
        annotations:
          summary: High Load Avarage
      - alert: High Filesystem Usage
        expr: ((node_filesystem_size_bytes{mountpoint="/", } - node_filesystem_free_bytes{mountpoint="/"})/node_filesystem_size_bytes{mountpoint="/"})*100 > 75
        for: 3m
        labels:
          severity: mail
        annotations:
          summary: High Filesystem Usage
      - alert: Mongo is down
        expr: mongodb_up < 1
        for: 1m
        labels:
          severity: mail
        annotations:
          summary: Mongo is down
      - alert: Mysql is down
        expr: mysql_up < 1
        for: 1m
        labels:
          severity: mail
        annotations:
          summary: Mysql is down
      - alert: Postgresql-k8s is down
        expr: pg_up{instance="postgres-exporter.db.svc.cluster.local:9187", job="postgres-local"} < 1
        for: 1m
        labels:
          severity: mail
        annotations:
          summary: Postgresql-k8s is down
      - alert: Postgresql-apps is down
        expr: pg_up{instance="postgres-postgresql-metrics.db.svc.cluster.local:9187", job="postgres"} < 1
        for: 1m
        labels:
          severity: mail
        annotations:
          summary: Postgresql-apps is down
      - alert: KubeJobFailed
        expr: kube_job_failed{job="kube-state-metrics",namespace=~".*"} > 0
        for: 10m
        labels:
          severity: mail
        annotations:
          summary: Job failed to complete.
      - alert: CPUThrottlingHigh
        expr: sum by (cluster, container, pod, namespace) (increase(container_cpu_cfs_throttled_periods_total{container!=""}[5m])) / sum by (cluster, container, pod, namespace) (increase(container_cpu_cfs_periods_total[5m])) > (25 / 100)
        for: 5m
        labels:
          severity: mail
        annotations:
          summary: Processes experience elevated CPU throttling.
      - alert: KubePersistentVolumeFillingUp
        expr: kubelet_volume_stats_available_bytes  / kubelet_volume_stats_capacity_bytes < 0.15
        for: 1m
        labels:
          severity: mail
        annotations:
          summary: PersistentVolume is filling up.
      - alert: KubePersistentVolumeFillingUp
        expr: (kubelet_volume_stats_available_bytes / kubelet_volume_stats_capacity_bytes) < 0.15 and predict_linear(kubelet_volume_stats_available_bytes[6h], 4 * 24 * 3600) < 0
        for: 1m
        labels:
          severity: mail
        annotations:
          summary: PersistentVolume is filling up in 4 days.
      - alert: KubePodCrashLooping
        expr: max_over_time(kube_pod_container_status_waiting_reason{job="kube-state-metrics",namespace=~".*",reason="CrashLoopBackOff"}[5m]) >= 1
        for: 5m
        labels:
          severity: mail
        annotations:
          summary: Pod is crash looping.
      - alert: KubePodNotReady
        expr: sum by (namespace, pod, cluster) (max by (namespace, pod, cluster) (kube_pod_status_phase{job="kube-state-metrics",namespace=~".*",phase=~"Pending|Unknown|Failed"}) * on (namespace, pod, cluster) group_left (owner_kind) topk by (namespace, pod, cluster) (1, max by (namespace, pod, owner_kind, cluster) (kube_pod_owner{owner_kind!="Job"}))) > 0
        for: 15m
        labels:
          severity: mail
        annotations:
          summary: Pod has been in a non-ready state for more than 15 minutes.
      - alert: KubeNodeNotReady
        expr: kube_node_status_condition{condition="Ready",job="kube-state-metrics",status="true"} == 0
        for: 1m
        labels:
          severity: mail
        annotations:
          summary: Node is not ready.
      - alert: KubeNodeUnreachable
        expr: (kube_node_spec_taint{effect="NoSchedule",job="kube-state-metrics",key="node.kubernetes.io/unreachable"} unless ignoring (key, value) kube_node_spec_taint{job="kube-state-metrics",key=~"ToBeDeletedByClusterAutoscaler|cloud.google.com/impending-node-termination|aws-node-termination-handler/spot-itn"}) == 1
        for: 1m
        labels:
          severity: mail
        annotations:
          summary: Node is unreachable.
      - alert: TargetDown
        expr: 100 * (count by (cluster, job, namespace, service) (up == 0) / count by (cluster, job, namespace, service) (up)) > 10
        for: 1m
        labels:
          severity: mail
        annotations:
          summary: One or more targets are unreachable.
      - alert: PVC is full!
        expr: longhorn_volume_actual_size_bytes/longhorn_volume_capacity_bytes > 0.85
        for: 1m
        labels:
          severity: mail
        annotations:
          summary: One or more PVC is >85% utilized.

  prometheus.yaml: |-
    global:
      scrape_interval: 5s
      evaluation_interval: 5s
      external_labels:
        cluster: prometheus
    rule_files:
      - /etc/prometheus/prometheus.rules
    alerting:
      alertmanagers:
      - scheme: http
        static_configs:
        - targets:
          - "alertmanager.monitoring.svc:9093"
    scrape_configs:
      - job_name: mysql-staging
        scrape_interval: 45s
        scrape_timeout:  30s
        metrics_path: "/metrics"
        static_configs:
        - targets:
          - mysqld-exporter.db.svc.cluster.local:9104

      - job_name: 'kubernetes-longhorn-manager'
        kubernetes_sd_configs:
          - role: pod
        relabel_configs:
          - source_labels: [__meta_kubernetes_pod_label_app]
            action: keep
            regex: longhorn-manager
          - source_labels: [__address__]
            action: replace
            target_label: __address__
            regex: ([^:]+)(?::\d+)?
            replacement: $1:9500
          - action: replace
            target_label: __metrics_path__
            replacement: /metrics

      - job_name: postgres
        scrape_interval: 45s
        scrape_timeout:  30s
        metrics_path: "/metrics"
        static_configs:
        - targets:
          - postgres-postgresql-metrics.db.svc.cluster.local:9187

      - job_name: postgres-local
        scrape_interval: 45s
        scrape_timeout:  30s
        metrics_path: "/metrics"
        static_configs:
        - targets:
          - postgres-exporter.db.svc.cluster.local:9187

      - job_name: rspamd
        scrape_interval: 45s
        scrape_timeout:  30s
        metrics_path: "/metrics"
        static_configs:
        - targets:
          - rspamd.mail.svc.cluster.local:11334

      - job_name: connectivity-exporter
        scrape_interval: 45s
        scrape_timeout:  30s
        static_configs:
          - targets:
            - connectivity-exporter.connectivity-exporter.svc.cluster.local:9090

      - job_name: redis-mail
        scrape_interval: 45s
        scrape_timeout:  30s
        metrics_path: "/metrics"
        static_configs:
        - targets:
          - redis.mail.svc.cluster.local:9121

      - job_name: redis-nextcloud
        scrape_interval: 45s
        scrape_timeout:  30s
        metrics_path: "/metrics"
        static_configs:
        - targets:
          - redis.nextcloud.svc.cluster.local:9121

      - job_name: traefik
        scrape_interval: 45s
        scrape_timeout:  30s
        metrics_path: "/metrics"
        static_configs:
        - targets:
          - traefik.traefik.svc.cluster.local:9100

      - job_name: redis-mastodon
        scrape_interval: 45s
        scrape_timeout:  30s
        metrics_path: "/metrics"
        static_configs:
        - targets:
          - redis.mastodon.svc.cluster.local:9121

      - job_name: redis-dawarich
        scrape_interval: 45s
        scrape_timeout:  30s
        metrics_path: "/metrics"
        static_configs:
        - targets:
          - redis-dawarich.dawarich.svc.cluster.local:9121

      - job_name: mongodb
        scrape_interval: 45s
        scrape_timeout:  30s
        metrics_path: "/metrics"
        static_configs:
        - targets:
          - mongo-exporter.db.svc.cluster.local:9216

      - job_name: external
        scrape_interval: 45s
        scrape_timeout:  30s
        metrics_path: "/metrics"
        static_configs:
        - targets:
          - backup.andreybondarenko.com:9090

      - job_name: unifi
        scrape_interval: 45s
        scrape_timeout:  30s
        metrics_path: "/metrics"
        static_configs:
        - targets:
          - unifi-poller.unifi.svc.cluster.local:9130
      - job_name: grafana
        scrape_interval: 45s
        scrape_timeout:  30s
        metrics_path: "/metrics"
        static_configs:
        - targets:
          - grafana.monitoring.svc.cluster.local:3000
      - job_name: prometheus
        scrape_interval: 45s
        scrape_timeout:  30s
        metrics_path: "/metrics"
        static_configs:
        - targets:
          - prometheus-service.monitoring.svc.cluster.local:9090
      - job_name: thanos-querier
        scrape_interval: 45s
        scrape_timeout:  30s
        metrics_path: "/metrics"
        static_configs:
        - targets:
          - thanos-querier.monitoring.svc.cluster.local:9090
      - job_name: thanos-store-gateway
        scrape_interval: 45s
        scrape_timeout:  30s
        metrics_path: "/metrics"
        static_configs:
        - targets:
          - thanos-store-gateway.monitoring.svc.cluster.local:10902
      - job_name: thanos-compactor
        scrape_interval: 45s
        scrape_timeout:  30s
        metrics_path: "/metrics"
        static_configs:
        - targets:
          - thanos-compactor.monitoring.svc.cluster.local:10902
      - job_name: clamav-exporter
        scrape_interval: 45s
        scrape_timeout:  30s
        metrics_path: "/metrics"
        static_configs:
        - targets:
          - clamav.clamav.svc.cluster.local:9906
      - job_name: 'node-exporter'
        kubernetes_sd_configs:
          - role: endpointslice
        relabel_configs:
          - source_labels: [__meta_kubernetes_service_annotation_prometheus_io_scrape]
            action: keep
            regex: true

          - source_labels: [__meta_kubernetes_service_name]
            action: keep
            regex: node-exporter

          - source_labels: [__address__, __meta_kubernetes_service_annotation_prometheus_io_port]
            action: replace
            target_label: __address__
            regex: ([^:]+)(?::\d+)?;(\d+)
            replacement: $1:$2

          - source_labels: [__meta_kubernetes_pod_node_name]
            target_label: kubernetes_node

      - job_name: 'kubernetes-apiservers'
        kubernetes_sd_configs:
        - role: endpointslice
        scheme: https
        tls_config:
          ca_file: /var/run/secrets/kubernetes.io/serviceaccount/ca.crt
        bearer_token_file: /var/run/secrets/kubernetes.io/serviceaccount/token
        relabel_configs:
        - source_labels: [__meta_kubernetes_namespace, __meta_kubernetes_endpointslice_service_name, __meta_kubernetes_endpointslice_port_name]
          action: keep
          regex: default;kubernetes;https

      - job_name: 'kubernetes-nodes'
        scheme: https
        tls_config:
          ca_file: /var/run/secrets/kubernetes.io/serviceaccount/ca.crt
        bearer_token_file: /var/run/secrets/kubernetes.io/serviceaccount/token
        kubernetes_sd_configs:
        - role: node
        relabel_configs:
        - action: labelmap
          regex: __meta_kubernetes_node_label_(.+)
        - target_label: __address__
          replacement: kubernetes.default.svc:443
        - source_labels: [__meta_kubernetes_node_name]
          target_label: __metrics_path__
          regex: (.+)
          replacement: /api/v1/nodes/${1}/proxy/metrics

      - job_name: 'kubernetes-pods'
        kubernetes_sd_configs:
        - role: pod
        relabel_configs:
        - source_labels: [__meta_kubernetes_pod_annotation_prometheus_io_scrape]
          action: keep
          regex: true
        - source_labels: [__meta_kubernetes_pod_annotation_prometheus_io_path]
          action: replace
          target_label: __metrics_path__
          regex: (.+)
        - source_labels: [__address__, __meta_kubernetes_pod_annotation_prometheus_io_port]
          action: replace
          regex: ([^:]+)(?::\d+)?;(\d+)
          replacement: $1:$2
          target_label: __address__
        - action: labelmap
          regex: __meta_kubernetes_pod_label_(.+)
        - source_labels: [__meta_kubernetes_namespace]
          action: replace
          target_label: kubernetes_namespace
        - source_labels: [__meta_kubernetes_pod_name]
          action: replace
          target_label: kubernetes_pod_name

      - job_name: 'kube-state-metrics'
        static_configs:
          - targets: ['kube-state-metrics.kube-system.svc.cluster.local:8080']

      - job_name: 'kubernetes-cadvisor'
        scheme: https
        tls_config:
          ca_file: /var/run/secrets/kubernetes.io/serviceaccount/ca.crt
        bearer_token_file: /var/run/secrets/kubernetes.io/serviceaccount/token
        kubernetes_sd_configs:
        - role: node
        relabel_configs:
        - action: labelmap
          regex: __meta_kubernetes_node_label_(.+)
        - target_label: __address__
          replacement: kubernetes.default.svc:443
        - source_labels: [__meta_kubernetes_node_name]
          regex: (.+)
          target_label: __metrics_path__
          replacement: /api/v1/nodes/${1}/proxy/metrics/cadvisor

      - job_name: 'kubernetes-service-endpoints'
        kubernetes_sd_configs:
        - role: endpointslice
        relabel_configs:
        - source_labels: [__meta_kubernetes_service_annotation_prometheus_io_scrape]
          action: keep
          regex: true
        - source_labels: [__meta_kubernetes_service_annotation_prometheus_io_scheme]
          action: replace
          target_label: __scheme__
          regex: (https?)
        - source_labels: [__meta_kubernetes_service_annotation_prometheus_io_path]
          action: replace
          target_label: __metrics_path__
          regex: (.+)
        - source_labels: [__address__, __meta_kubernetes_service_annotation_prometheus_io_port]
          action: replace
          target_label: __address__
          regex: ([^:]+)(?::\d+)?;(\d+)
          replacement: $1:$2
        - action: labelmap
          regex: __meta_kubernetes_service_label_(.+)
        - source_labels: [__meta_kubernetes_namespace]
          action: replace
          target_label: kubernetes_namespace
        - source_labels: [__meta_kubernetes_endpointslice_service_name]
          action: replace
          target_label: kubernetes_name
